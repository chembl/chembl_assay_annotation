{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated Cross Validation for NER method extraction from assay description\n",
    "The notebook manages the main pipeline for models training/testing cross validation.\n",
    "* Reads the annotated dataset\n",
    "* It split the training data into chunks according to the cross validations folds settings\n",
    "* Generates the jsonl input files\n",
    "* It executes the pipeline by training and testing accross all chunks of data\n",
    "\n",
    "The main pipeline is contained in the folder 'ner_assays' and it's set up to accept the input files:\n",
    "* assays_eval.jsonl\n",
    "* assays_training.jsonl\n",
    "\n",
    "After execution of input data it generates the following outputs:\n",
    "* model-best\n",
    "* model-last\n",
    "* metrics.json\n",
    "\n",
    "While executing CV, each of the chunks data inputs is copied to the pipeline folder. The pipeline is executed with those files and outputs generated are copied back out to the specified path.\n",
    "\n",
    "For live testing of a specific model, the output files of such model can be moved to the output folder and execute the pipeline commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, spacy, os\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import subprocess\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings for display (if needed)\n",
    "pd.set_option('display.max_colwidth', None)  # Set to None to display the full column width\n",
    "pd.set_option('display.max_rows', None)      # Set to None to display al\n",
    "\n",
    "#check path to language\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\") \n",
    "except OSError:\n",
    "    print(\"Model not found. Downloading 'en_core_web_sm'\")\n",
    "    os.system(\"python -m spacy download en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to obtain jsonl input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to generate jsonl file with tabulated data for model training\n",
    "def generate_jsonl(df,f): #dataframe and output file\n",
    "    # Load spaCy model \n",
    "    nlp = spacy.load(\"en_core_web_sm\")  # Adjust the model name if needed\n",
    "\n",
    "    data = []\n",
    "    for index, row in df.iterrows():\n",
    "        sentence = row['description'].lower()\n",
    "            \n",
    "        # Tokenization with spaCy\n",
    "        doc = nlp(sentence)\n",
    "        token_data = []\n",
    "        for i, token in enumerate(doc):\n",
    "            token_data.append({\"text\": token.text, \"start\": token.idx, \"end\": token.idx + len(token), \"id\": i })\n",
    "\n",
    "        # Entity Labeling\n",
    "        if not pd.isna(row['method']):\n",
    "            entity = row['method'].lower()\n",
    "            start_idx = sentence.find(entity)\n",
    "            end_idx = start_idx + len(entity)\n",
    "            if start_idx != -1:\n",
    "                token_st = [entry for entry in token_data if entry['start'] == start_idx][0]['id']\n",
    "                token_en = [entry for entry in token_data if entry['end'] == end_idx][0]['id']\n",
    "                spans = [{\"start\": start_idx, \"end\": end_idx, \n",
    "                        \"token_start\": token_st, \n",
    "                        \"token_end\": token_en, \n",
    "                        \"label\": \"METHOD\"}]\n",
    "            else:\n",
    "                spans = []\n",
    "        else:\n",
    "            spans=[]\n",
    "\n",
    "        #print(sentence, \"|\", entity, \"|\", start_idx, \"|\", end_idx, sentence[start_idx], sentence[end_idx])\n",
    "\n",
    "        # JSONL Entry\n",
    "        entry = {\n",
    "            \"text\": sentence,\n",
    "            \"meta\": {},  # Add metadata if needed\n",
    "            \"_input_hash\": hash(sentence),  # Some hash function\n",
    "            \"_task_hash\": -1,  # Placeholder\n",
    "            \"tokens\": token_data,\n",
    "            \"spans\": spans,\n",
    "            \"answer\": \"accept\"  # Replace if needed\n",
    "        }\n",
    "        data.append(entry)\n",
    "\n",
    "    #writing jsonl file\n",
    "    for item in data:\n",
    "        json.dump(item,f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training: Binding assays and functional assays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main annotated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/assays_data.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Setting up the Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpath = \"Model_cv\"\n",
    "rpath = \"Results\"\n",
    "os.makedirs(mpath, exist_ok=True)\n",
    "os.makedirs(rpath, exist_ok=True)\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=5, random_state=20172023)\n",
    "for fold, (train_index, test_index) in enumerate(rkf.split(dataset)):\n",
    "    train_df = dataset.iloc[train_index]\n",
    "    test_df = dataset.iloc[test_index]\n",
    "    path = os.path.join(mpath,'chunk{}'.format(fold))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "    # Write to JSONL files\n",
    "    with open(os.path.join(path,'assays_eval.jsonl'), 'w') as f:\n",
    "        generate_jsonl(test_df, f)# Generate JSONL file with testing data \n",
    "    with open(os.path.join(path,'assays_training.jsonl'), 'w') as f:\n",
    "        generate_jsonl(train_df, f)# Generate JSONL file with testing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Executing Cross-Validation: Move inputs to pipeline, run pipeline, take outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in Path(mpath).iterdir():\n",
    "    if f.is_dir():\n",
    "        chunk = f.name\n",
    "        eval = os.path.join(f,'assays_eval.jsonl')\n",
    "        train = os.path.join(f,'assays_training.jsonl')\n",
    "\n",
    "        #Copy the current input files to the pipeline path\n",
    "        shutil.copy(eval, os.path.join('ner_assays/assets/'))\n",
    "        shutil.copy(train, os.path.join('ner_assays/assets/'))\n",
    "\n",
    "        #Run the pipeline\n",
    "        os.chdir('ner_assays')\n",
    "        command = 'python3 -m weasel run model-cv'\n",
    "        subprocess.run(command, shell=True, capture_output=True, text=True)\n",
    "        os.chdir('../')\n",
    "        \n",
    "        #Move outputs to the chunk folder\n",
    "        opath = os.path.join(f,'training')\n",
    "        shutil.copytree('ner_assays/training', opath, dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-Validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_all = []\n",
    "\n",
    "# Extract all metrics from different chunks\n",
    "for f in Path(mpath).iterdir():\n",
    "    if f.is_dir():\n",
    "        chunk = f.name\n",
    "        metricspath = os.path.join(f,'training/metrics.json')\n",
    "        # Open JSON File\n",
    "        with open(metricspath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        metrics  = {key: data[key] for key in ['ents_p', 'ents_r', 'ents_f']}\n",
    "        metrics['chunk'] = chunk\n",
    "        metrics_all.append(metrics)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_all).sort_values(by=['ents_f','ents_p', 'ents_r']).round(2).set_index('chunk') #moves chunk column as index to calculate mean of all\n",
    "metrics_df.loc['mean'] = metrics_df.mean().round(2) #calculates mean of all features\n",
    "metrics_df.reset_index().to_csv(os.path.join(rpath,'cv_metrics.tsv'), sep='\\t', index=False) #Saves as csv file and resets normal index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk8</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chunk12</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chunk6</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chunk23</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chunk19</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chunk22</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chunk1</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chunk17</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chunk14</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chunk11</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chunk0</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>chunk13</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chunk2</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>chunk24</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>chunk3</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>chunk21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>chunk4</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>chunk7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>chunk9</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chunk15</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>chunk5</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>chunk16</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>chunk10</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chunk18</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>chunk20</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunk  Precision  Recall  F-score\n",
       "0    chunk8       0.87    0.93     0.90\n",
       "1   chunk12       0.89    0.94     0.91\n",
       "2    chunk6       0.92    0.91     0.91\n",
       "3   chunk23       0.89    0.94     0.92\n",
       "4   chunk19       0.91    0.93     0.92\n",
       "5   chunk22       0.94    0.91     0.93\n",
       "6    chunk1       0.90    0.96     0.93\n",
       "7   chunk17       0.94    0.92     0.93\n",
       "8   chunk14       0.95    0.91     0.93\n",
       "9   chunk11       0.95    0.92     0.93\n",
       "10   chunk0       0.94    0.94     0.94\n",
       "11  chunk13       0.91    0.97     0.94\n",
       "12   chunk2       0.92    0.96     0.94\n",
       "13  chunk24       0.95    0.93     0.94\n",
       "14   chunk3       0.93    0.96     0.95\n",
       "15  chunk21       0.94    0.95     0.95\n",
       "16   chunk4       0.97    0.93     0.95\n",
       "17   chunk7       0.95    0.95     0.95\n",
       "18   chunk9       0.93    0.97     0.95\n",
       "19  chunk15       0.93    0.97     0.95\n",
       "20   chunk5       0.93    0.98     0.95\n",
       "21  chunk16       0.95    0.96     0.95\n",
       "22  chunk10       0.95    0.95     0.95\n",
       "23  chunk18       0.97    0.96     0.96\n",
       "24  chunk20       0.98    0.98     0.98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting data for cross validation\n",
    "mpath = \"Model_cv\"\n",
    "rpath = \"Results\"\n",
    "#Parse metrics\n",
    "metrics = pd.read_csv(os.path.join(rpath,'cv_metrics.tsv'), sep='\\t')\n",
    "metrics = metrics[metrics.chunk != 'mean'].rename(columns={'ents_f':'F-score','ents_p':'Precision', 'ents_r': 'Recall'})\n",
    "display(metrics)\n",
    "\n",
    "\n",
    "# Melt the DataFrame\n",
    "df_melted = metrics.melt('chunk', var_name='Metric', value_name='value')\n",
    "\n",
    "# Compute min and max values across all metrics\n",
    "min_value = df_melted['value'].min()\n",
    "max_value = df_melted['value'].max()\n",
    "\n",
    "# Define a list of green colors\n",
    "green_colors = [\"#9ecae1\", \"#045a8d\", \"#006d2c\"]  # Light to dark green\n",
    "\n",
    "# Plotting metrics\n",
    "chart = alt.Chart(df_melted).mark_line(point=True).encode(\n",
    "    x=alt.X('chunk:O', sort=None),\n",
    "    y=alt.Y('value:Q', scale=alt.Scale(domain=[min_value, max_value])),\n",
    "    color=alt.Color('Metric:N', scale=alt.Scale(domain=['F-score','Precision','Recall'], range=green_colors)),\n",
    "    tooltip=['chunk', 'Metric', 'value']\n",
    ")\n",
    "\n",
    "# Save the chart as png\n",
    "output_filename = \"cross_validation_metrics.png\"  # Choose your filename\n",
    "output_path = os.path.join(rpath, output_filename) # Save in the same directory as metrics.csv\n",
    "chart.save(output_path)\n",
    "\n",
    "# Save the chart as interactive html\n",
    "output_filename = \"cross_validation_metrics.html\"  # Choose your filename\n",
    "output_path = os.path.join(rpath, output_filename) # Save in the same directory as metrics.csv\n",
    "chart.save(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Mean and SD rows (ignoring first column, 'Mean'/'SD' in first column):\n",
      "      chunk  Precision  Recall  F-score\n",
      "0    chunk8       0.87    0.93     0.90\n",
      "1   chunk12       0.89    0.94     0.91\n",
      "2    chunk6       0.92    0.91     0.91\n",
      "3   chunk23       0.89    0.94     0.92\n",
      "4   chunk19       0.91    0.93     0.92\n",
      "5   chunk22       0.94    0.91     0.93\n",
      "6    chunk1       0.90    0.96     0.93\n",
      "7   chunk17       0.94    0.92     0.93\n",
      "8   chunk14       0.95    0.91     0.93\n",
      "9   chunk11       0.95    0.92     0.93\n",
      "10   chunk0       0.94    0.94     0.94\n",
      "11  chunk13       0.91    0.97     0.94\n",
      "12   chunk2       0.92    0.96     0.94\n",
      "13  chunk24       0.95    0.93     0.94\n",
      "14   chunk3       0.93    0.96     0.95\n",
      "15  chunk21       0.94    0.95     0.95\n",
      "16   chunk4       0.97    0.93     0.95\n",
      "17   chunk7       0.95    0.95     0.95\n",
      "18   chunk9       0.93    0.97     0.95\n",
      "19  chunk15       0.93    0.97     0.95\n",
      "20   chunk5       0.93    0.98     0.95\n",
      "21  chunk16       0.95    0.96     0.95\n",
      "22  chunk10       0.95    0.95     0.95\n",
      "23  chunk18       0.97    0.96     0.96\n",
      "24  chunk20       0.98    0.98     0.98\n",
      "25     Mean       0.93    0.95     0.94\n",
      "26       SD       0.03    0.02     0.02\n"
     ]
    }
   ],
   "source": [
    "# Separate the first column from the rest\n",
    "first_column = metrics.iloc[:, 0:1] # Selects the first column\n",
    "numerical_columns_df = metrics.iloc[:, 1:] # Selects all columns from the second one onwards\n",
    "\n",
    "# Calculate the mean and standard deviation for the numerical columns\n",
    "mean_row_data = numerical_columns_df.mean().round(2)\n",
    "std_row_data = numerical_columns_df.std().round(2)\n",
    "\n",
    "# Create Series for the new rows with \"Mean\" and \"SD\" in the first column\n",
    "mean_series = pd.Series({'chunk': 'Mean', **mean_row_data.to_dict()})\n",
    "std_series = pd.Series({'chunk': 'SD', **std_row_data.to_dict()})\n",
    "\n",
    "# Convert these Series to DataFrames (as single rows)\n",
    "mean_df_to_add = pd.DataFrame([mean_series])\n",
    "std_df_to_add = pd.DataFrame([std_series])\n",
    "\n",
    "# Concatenate the original DataFrame with the new mean and std dev rows\n",
    "df_final = pd.concat([metrics, mean_df_to_add, std_df_to_add], ignore_index=True)\n",
    "\n",
    "print(\"DataFrame with Mean and SD rows (ignoring first column, 'Mean'/'SD' in first column):\")\n",
    "print(df_final)\n",
    "df_final.to_csv(os.path.join(rpath,'cv_metrics.tsv'), sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nerenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
