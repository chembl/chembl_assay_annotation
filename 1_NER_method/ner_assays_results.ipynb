{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER model for method extraction in assay description - Results\n",
    "The notebook analyses the annotated data stats and the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input/output paths\n",
    "dpath = \"data\"\n",
    "rpath = \"Results\"\n",
    "spath = \"Results/Sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads chembl 35 dataset without annotations. Check assays_description/2_broad_assay_category/chembl_35_broad_predictions.ipynb for more details on how to generate this file \n",
    "chembl_assays = pd.read_csv(os.path.join(dpath, 'chembl_35_all_BF_assays.txt'), sep='\\t')\n",
    "chembl_assays = chembl_assays.drop(['Unnamed: 0'] ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads training set (with manually annotated data) and chembl35 dataset with NER annotated data\n",
    "ann_assays = pd.read_csv(os.path.join(dpath, 'assays_data.csv'), sep='\\t')\n",
    "ner_assays = pd.read_csv(os.path.join(rpath, 'ner_chembl_35.tsv'), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General numbers and commonly identified methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check annotated methods in training set: unique, no method, other numbers, etc\n",
    "#Unique methods strings\n",
    "print(ann_assays.method.nunique())\n",
    "\n",
    "#Counts methods strings frequency in assays\n",
    "value_counts = ann_assays.method.value_counts()\n",
    "print(value_counts.nlargest(20))\n",
    "\n",
    "#Counts descriptions without methods\n",
    "len(ann_assays[ann_assays.method.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check proportion of F and B assays in all (non annotated) chembl 35 data\n",
    "allassays = len(chembl_assays)                              # total number of assays in ChEMBL 35 dataset\n",
    "all_B = len(chembl_assays[chembl_assays.assay_type == 'B']) # assays of type B\n",
    "bprop = all_B*100/len(chembl_assays)                        # proportion of assays type B\n",
    "all_F = len(chembl_assays[chembl_assays.assay_type == 'F']) # assays of type F\n",
    "fprop = all_F*100/len(chembl_assays)                        # proportion of assays type F\n",
    "print(allassays)\n",
    "print(all_B)\n",
    "print(all_F)\n",
    "print(bprop)\n",
    "print(fprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check proportion of B and F assays where a method hs been found\n",
    "ner_found = ner_assays[~ner_assays.method.isnull()] # assays in dataset with a method found by NER model\n",
    "ann_B = len(ner_found[ner_found.assay_type == 'B']) # assays of type B with method\n",
    "annbprop = ann_B*100/all_B                          # proportion of annotated B\n",
    "ann_F = len(ner_found[ner_found.assay_type == 'F']) # assays of type F with method\n",
    "annfprop = ann_F*100/all_F                          # proportion of type F\n",
    "print(len(ner_found))\n",
    "print(ann_B)\n",
    "print(ann_F)\n",
    "print(annbprop)\n",
    "print(annfprop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks predicted methods by NER model\n",
    "print(ner_assays.method.nunique())\n",
    "\n",
    "# method frequency among assays description\n",
    "value_counts = ner_assays.method.value_counts()\n",
    "print(value_counts.nlargest(20))\n",
    "fullset = value_counts.reset_index().sort_values(by='count',ascending=False)\n",
    "fullset.to_csv(os.path.join(rpath, 'ner_chembl_35_methods.tsv'), sep='\\t', index=False)\n",
    "\n",
    "# Count assays with and without methods\n",
    "print(len(ner_assays[ner_assays.method.isnull()]))\n",
    "print(len(ner_assays[~ner_assays.method.isnull()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling data and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stratified sample set with annotated methods\n",
    "display(ner_assays.columns)\n",
    "\n",
    "training_assays = ann_assays.assay_id.unique()\n",
    "ner_b = ner_assays[(ner_assays.assay_type == 'B') & (~ner_assays.assay_id.isin(training_assays))]\n",
    "ner_f = ner_assays[(ner_assays.assay_type == 'F') & (~ner_assays.assay_id.isin(training_assays))]\n",
    "\n",
    "sample_b = ner_b.sample(n=int(round(bprop,0)), random_state=412)  # Set random_state for reproducibility\n",
    "sample_f = ner_f.sample(n=int(round(fprop, 0)), random_state=412)\n",
    "\n",
    "method_sample = pd.concat([sample_b, sample_f])[['assay_id', 'assay_type', 'description', 'method']]\n",
    "\n",
    "# Shuffle the final sample (optional, but good practice)\n",
    "#final_sample = final_sample.sample(frac=1, random_state=42)  # frac=1 shuffles all rows\n",
    "\n",
    "method_sample.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the final sample dataset into a csv file\n",
    "method_sample.to_csv(os.path.join(spath, 'sample_subset_chembl35.tsv'), sep='\\t', index=False)\n",
    "print(method_sample.groupby('assay_type').count())\n",
    "\n",
    "# edit the final sample dataset without NER method for blind curation into a csv file\n",
    "blind_method_sample = method_sample.drop(columns='method', axis=1)\n",
    "\n",
    "# writes blind sample data into tsv file \n",
    "blind_method_sample.to_csv(os.path.join(spath, 'sample_subset_chembl35_blind.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load blind sample data with annotations by curators\n",
    "blind_method_sample_ann = pd.read_excel(os.path.join(spath, 'sample_subset_chembl35_blind_ann.xlsx'), skiprows=[0]).rename(columns={'extracted method':'annotated_method'})\n",
    "\n",
    "#merging NER annotations and curators annotations\n",
    "method_sample = method_sample.merge(blind_method_sample_ann, on='assay_id', how='left', suffixes=('', '_ann'))\n",
    "method_sample = method_sample.drop(columns=[col for col in method_sample.columns if col.endswith('_ann')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample data 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select stratified sample set 2 with annotated methods\n",
    "display(ner_assays.columns)\n",
    "\n",
    "training_assays = ann_assays.assay_id.unique()\n",
    "ner_b = ner_assays[(ner_assays.assay_type == 'B') & (~ner_assays.assay_id.isin(training_assays))] #checking of used assay_ids in sample data 1 could have been done here, but if modified now random_state could be affected\n",
    "ner_f = ner_assays[(ner_assays.assay_type == 'F') & (~ner_assays.assay_id.isin(training_assays))]\n",
    "\n",
    "sample_b = ner_b.sample(n=int(round(bprop,0)), random_state=266)  # Set random_state for reproducibility\n",
    "sample_f = ner_f.sample(n=int(round(fprop, 0)), random_state=266)\n",
    "\n",
    "method_sample2 = pd.concat([sample_b, sample_f])[['assay_id', 'assay_type', 'description', 'method']]\n",
    "\n",
    "#method_sample2.assay_id.isin(method_sample.assay_id.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes the final sample dataset 2 #into a csv file\n",
    "method_sample2.to_csv(os.path.join(spath, 'sample_subset2_chembl35.tsv'), sep='\\t', index=False)\n",
    "print(method_sample2.groupby('assay_type').count())\n",
    "\n",
    "# Writes the final sample dataset without NER method for blind curation into a csv file\n",
    "blind_method_sample2 = method_sample2.drop(columns='method', axis=1)\n",
    "#display(blind_method_sample)\n",
    "blind_method_sample2.to_csv(os.path.join(spath, 'sample_subset2_chembl35_blind.tsv'), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load blind sample data 2 with annotations by curators (when available)\n",
    "blind_method_sample2_ann = pd.read_excel(os.path.join(spath, 'sample_subset2_chembl35_blind_ann.xlsx'), skiprows=[0]).rename(columns={'method':'annotated_method'})\n",
    "\n",
    "#merging NER annotations and curators annotations\n",
    "method_sample2 = method_sample2.merge(blind_method_sample2_ann, on='assay_id', how='left', suffixes=('', '_ann'))\n",
    "method_sample2 = method_sample2.drop(columns=[col for col in method_sample2.columns if col.endswith('_ann')])\n",
    "method_sample2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix in both sample datasets\n",
    "For now it just considers the first sample data as the second one is missing annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contcatenating the two sample datasets (when available)\n",
    "final_sample = pd.concat([method_sample,method_sample2])\n",
    "#final_sample = method_sample  #delete when concatenation of both sample datas possible\n",
    "\n",
    "#Assigning labels for predictions vs annotations\n",
    "final_sample['evaluation'] = np.select(\n",
    "    [\n",
    "        final_sample.method == final_sample.annotated_method,  # TP (Highest priority)\n",
    "        (final_sample.method.isna()) & (final_sample.annotated_method.isna()),  # FP\n",
    "        (final_sample.method.isna()) & (final_sample.annotated_method.notna()),  # FP\n",
    "        (final_sample.method.notna()) & (final_sample.annotated_method.isna()),  # FN\n",
    "    ],\n",
    "    ['TP', 'TN', 'FN', 'FP', ],\n",
    "    default='PM')\n",
    "\n",
    "# values for the confusion matrix\n",
    "final_sample.evaluation.value_counts()\n",
    "final_sample.to_csv(os.path.join(rpath, \"ner_chembl_35_sample_subset_evaluation.tsv\"), sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show examples with FP, FN, and partial matches\n",
    "display(final_sample[final_sample.evaluation.isin(['FP','FN','PM'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show examples with partial match and calculate lev distance \n",
    "sample_pm = final_sample[final_sample.evaluation == 'PM']\n",
    "\n",
    "def levenshtein_distance(str1, str2):\n",
    "    matrix = [[0 for _ in range(len(str2) + 1)] for _ in range(len(str1) + 1)]\n",
    "    for i in range(len(str1) + 1):\n",
    "        matrix[i][0] = i\n",
    "    for j in range(len(str2) + 1):\n",
    "        matrix[0][j] = j\n",
    "    for i in range(1, len(str1) + 1):\n",
    "        for j in range(1, len(str2) + 1):\n",
    "            if str1[i - 1] == str2[j - 1]:\n",
    "                matrix[i][j] = matrix[i - 1][j - 1]\n",
    "            else:\n",
    "                matrix[i][j] = min(\n",
    "                    matrix[i - 1][j] + 1,\n",
    "                    matrix[i][j - 1] + 1,\n",
    "                    matrix[i - 1][j - 1] + 1\n",
    "                )\n",
    "    return matrix[len(str1)][len(str2)]\n",
    "\n",
    "sample_pm['lev_distance'] = sample_pm.apply(lambda row: levenshtein_distance(row['method'], row['annotated_method']), axis=1)\n",
    "sample_pm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assays_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
